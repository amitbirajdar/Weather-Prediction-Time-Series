{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn-Hm2f5f2P2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Please Note:\n",
        "\n",
        "Instead of making new model everytime for every feature combination, I reinitialize the input data with necessary changes and run the previously created models. I cross verified if this method works correctly, and found that it actually does. Hence, instead of repeating code, I have re-run the models created in the begining of this file.\n",
        "\n",
        "I have repeated model creation twice since there was a major difference in the first and second part where first part only involves the temperature whereas second part onwards contains combination of features. For the second part and later, i use only one model, re-running it with different data inputs.\n",
        "\n",
        "Also, data exploration part is done along with the ARIMA model and hence, haven't repeated it here. Although, I have carried forward the preprocessing to this file from the ARIMA file.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb6xG3O3a27Q"
      },
      "source": [
        "'''Importing necessary libraries'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Flatten, SimpleRNN, Dropout\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3sfEc_bbCY9"
      },
      "source": [
        "'''reading data from csv'''\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Problem Set 6/ps6_trainvalid.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxzvxUKqhuZD"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn2rmJVBv3La"
      },
      "source": [
        "'''converting datetime column to datetime type and setting it as index'''\n",
        "\n",
        "data.datetime = pd.to_datetime(data.datetime)\n",
        "data.set_index(data.datetime, inplace=True)\n",
        "data.drop('datetime', inplace=True, axis=1)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_uSIAJZbclg"
      },
      "source": [
        "'''substituting null values with mean'''\n",
        "\n",
        "temp_mean = data.temperature.mean()\n",
        "humidity_mean = data.humidity.mean()\n",
        "pressure_mean = data.pressure.mean()\n",
        "\n",
        "data.temperature = data.temperature.fillna(temp_mean)\n",
        "data.humidity = data.humidity.fillna(humidity_mean)\n",
        "data.pressure = data.pressure.fillna(pressure_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV4fpka7dDBN"
      },
      "source": [
        "'''filling null value in weather with most common weather type'''\n",
        "\n",
        "data.weather = data.weather.fillna('sky is clear')\n",
        "data.wind_direction = data.wind_direction.fillna(0.0)\n",
        "data.wind_speed = data.wind_speed.fillna(0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDJSWjFh-W-"
      },
      "source": [
        "'''since wind direction is in degrees, we split it into its components - sin and cos and create two respective columns'''\n",
        "\n",
        "data['cos_wind'] = np.cos((data.wind_direction.values.reshape(len(data), 1)*np.pi)/180)\n",
        "data['sin_wind'] = np.sin((data.wind_direction.values.reshape(len(data), 1)*np.pi)/180)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_0a6v0cw40"
      },
      "source": [
        "'''checking final dataset for any null values'''\n",
        "\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjVkUGLiB06"
      },
      "source": [
        "'''dropping wind_direction since it is no longer needed as we have sin and cos components for it'''\n",
        "\n",
        "data = data.drop('wind_direction', axis=1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQAaBmUouXGx"
      },
      "source": [
        "'''looking at different weather types'''\n",
        "\n",
        "data.weather.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JEVJu3IoiwG"
      },
      "source": [
        "# Using only Temperature feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajN0Sh7EoiXt"
      },
      "source": [
        "'''using 360 hours to predict 60 hours in the future'''\n",
        "\n",
        "n_hours = 360\n",
        "X, Y = [], []\n",
        "for i in range(len(data)):\n",
        "  index = i + n_hours\n",
        "  if index > len(data) - 60:\n",
        "    break\n",
        "  x = data.temperature[i:index]\n",
        "  X.append(x)\n",
        "  y = data.temperature[index:index+60]\n",
        "  Y.append(y)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHScITX6o2vh"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5Wl44Fovwk"
      },
      "source": [
        "'''splitting data into training, validation and test data'''\n",
        "\n",
        "train_index = int(X.shape[0]*0.6)\n",
        "val_index = int(X.shape[0]*0.2)\n",
        "\n",
        "'''training data'''\n",
        "x_train = X[:train_index]\n",
        "y_train = Y[:train_index]\n",
        "\n",
        "'''validation data'''\n",
        "x_val = X[train_index:train_index+val_index]\n",
        "y_val = Y[train_index:train_index+val_index]\n",
        "\n",
        "'''test data'''\n",
        "x_test = X[train_index+val_index:]\n",
        "y_test = Y[train_index+val_index:]\n",
        "\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4aSgjR-pU0v"
      },
      "source": [
        "'''reshaping training and validation data'''\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnOdoZ9PyWZO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Baseline model with dense layer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsTKQePcpmzP"
      },
      "source": [
        "''''baseline model with only one dense layer'''\n",
        "\n",
        "baseline = Sequential([\n",
        "                       Flatten(input_shape=[360,1]),\n",
        "                       Dense(60)\n",
        "])\n",
        "baseline.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4T4a29Fpmoq"
      },
      "source": [
        "'''compiling baseline model'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(0.0001)\n",
        "baseline.compile(optimizer=opt, loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkLX3gL4qAbV"
      },
      "source": [
        "'''training baseline model'''\n",
        "\n",
        "baseline_history = baseline.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W15iw2cYqQ1H"
      },
      "source": [
        "'''plotting training and validation loss for baseline model'''\n",
        "\n",
        "plt.title('loss')\n",
        "plt.plot(baseline_history.history['loss'], label='training loss')\n",
        "plt.plot(baseline_history.history['val_loss'], label='validation loss')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pae_lqW4rMvx"
      },
      "source": [
        "'''making predictions'''\n",
        "\n",
        "baseline_y_pred = baseline.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1PPk4MrSQJ"
      },
      "source": [
        "'''calculating mean absolute error'''\n",
        "\n",
        "mean_absolute_error(y_test.reshape(y_test.shape[0], y_test.shape[1]), baseline_y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktDtBZJkyS1Z"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Simple RNN\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72_tUqjpyRt6"
      },
      "source": [
        "''''Sequential model with only one SimpleRNN layer'''\n",
        "\n",
        "simpleRNN = Sequential([\n",
        "                        SimpleRNN(5, input_shape=[None,1], activation='relu'),\n",
        "                        Dense(60)\n",
        "])\n",
        "simpleRNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnEwkE2_yRrK"
      },
      "source": [
        "'''compiling the model'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(0.01)\n",
        "simpleRNN.compile(optimizer=opt, loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apfdJLHeyRny"
      },
      "source": [
        "'''training phase'''\n",
        "\n",
        "simpleRNN_history = simpleRNN.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzU6jd6VyRmC"
      },
      "source": [
        "'''plotting training and validation loss for SimpleRNN model'''\n",
        "\n",
        "plt.plot(simpleRNN_history.history['loss'])\n",
        "plt.plot(simpleRNN_history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRoKVJwZyRiE"
      },
      "source": [
        "'''making predictions'''\n",
        "\n",
        "simpleRNN_y_pred = simpleRNN.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwLwHaMSzKHx"
      },
      "source": [
        "'''calculating mean absolute error'''\n",
        "\n",
        "mean_absolute_error(y_test, simpleRNN_y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odGJfD-t5rX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "LSTM\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-fJijLt5AL"
      },
      "source": [
        "''''Sequential model with only one LSTM layer'''\n",
        "\n",
        "\n",
        "lstm = Sequential([\n",
        "                   LSTM(10, activation='relu', return_sequences=True, input_shape=(360,1)),\n",
        "                   #Dropout(0.3),\n",
        "                   Flatten(),\n",
        "                   Dense(60)\n",
        "])                  \n",
        "lstm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS0_5l1auNZp"
      },
      "source": [
        "'''compiling the model and training'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.005)\n",
        "lstm.compile(optimizer=opt, loss='mean_absolute_error')\n",
        "lstm_history = lstm.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpTGsyqww1x"
      },
      "source": [
        "'''plotting training and validation loss for SimpleRNN model'''\n",
        "\n",
        "plt.plot(lstm_history.history['loss'][:])\n",
        "plt.plot(lstm_history.history['val_loss'][:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FaI7EPXw57M"
      },
      "source": [
        "'''making predictions and calculating mean absolute error'''\n",
        "\n",
        "lstm_ypred = lstm.predict(x_test)\n",
        "mean_absolute_error(y_test, lstm_ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "houqbgsI2WhD"
      },
      "source": [
        "# With features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uk5eH5Tc5zb"
      },
      "source": [
        "'''checking correlation between features'''\n",
        "\n",
        "data.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezX5bRhd2gIM"
      },
      "source": [
        "'''encoding categorical feature - weather'''\n",
        "new = pd.get_dummies(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRqVhwB62lQX"
      },
      "source": [
        "data.shape, new.shape, len(data.weather.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j50onggM3ZuW"
      },
      "source": [
        "'''using 360 hours to predict 60 hours in the future'''\n",
        "\n",
        "n_hours = 360\n",
        "X, Y = [], []\n",
        "for i in range(len(new)):\n",
        "  index = i + n_hours\n",
        "  if index > len(new) - 60:\n",
        "    break\n",
        "  x = new[i:index]\n",
        "  X.append(x)\n",
        "  y = new.temperature[index:index+60]\n",
        "  Y.append(y)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9dNJOgD4Ksw"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMcNOoa39If"
      },
      "source": [
        "'''splitting data into training, validation and test data'''\n",
        "\n",
        "train_index = int(X.shape[0]*0.6)\n",
        "val_index = int(X.shape[0]*0.2)\n",
        "\n",
        "'''training data'''\n",
        "x_train = X[:train_index]\n",
        "y_train = Y[:train_index]\n",
        "\n",
        "'''validation data'''\n",
        "x_val = X[train_index:train_index+val_index]\n",
        "y_val = Y[train_index:train_index+val_index]\n",
        "\n",
        "'''test data'''\n",
        "x_test = X[train_index+val_index:]\n",
        "y_test = Y[train_index+val_index:]\n",
        "\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rMAJ829tdCC"
      },
      "source": [
        "''''baseline model with only one dense layer'''\n",
        "\n",
        "baseplusft = Sequential([\n",
        "                         Flatten(input_shape=[360,31]),\n",
        "                         Dense(60)\n",
        "])\n",
        "baseplusft.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GZToG2Qtoib"
      },
      "source": [
        "'''compiling the model'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(0.0001)\n",
        "baseplusft.compile(optimizer=opt, loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZqBoom6ts8q"
      },
      "source": [
        "'''training phase'''\n",
        "\n",
        "baseplusft_history = baseplusft.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD1HPXe4u_el"
      },
      "source": [
        "'''plotting validation and training loss'''\n",
        "\n",
        "plt.plot(baseplusft_history.history['loss'])\n",
        "plt.plot(baseplusft_history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6pBNvDTun1q"
      },
      "source": [
        "'''making predictions'''\n",
        "baseplusft_ypred = baseplusft.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWD7J0z6utN8"
      },
      "source": [
        "'''calculating mean absolute error'''\n",
        "mean_absolute_error(y_test, baseplusft_ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhHc5iG8EHxr"
      },
      "source": [
        "''''Sequential model with only one SimpleRNN layer'''\n",
        "\n",
        "simpleRNNplusft = Sequential([\n",
        "                              SimpleRNN(24, input_shape=(360,31)),\n",
        "                              Dense(60)\n",
        "])\n",
        "simpleRNNplusft.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvJIV5VqEHuz"
      },
      "source": [
        "'''compiling the model'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(0.01)\n",
        "simpleRNNplusft.compile(optimizer=opt, loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0NK14AfEHr5"
      },
      "source": [
        "'''training phase'''\n",
        "\n",
        "simpleRNNplusft_history = simpleRNNplusft.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6VfvOWiEHpH"
      },
      "source": [
        "'''plotting validation and training loss'''\n",
        "\n",
        "plt.plot(simpleRNNplusft_history.history['loss'])\n",
        "plt.plot(simpleRNNplusft_history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Q-4oaSEHlk"
      },
      "source": [
        "'''making predictions'''\n",
        "\n",
        "simpleRNNplusft_ypred = simpleRNNplusft.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FvNaz7yEHjX"
      },
      "source": [
        "'''calculating mean absolute error'''\n",
        "\n",
        "mean_absolute_error(y_test, simpleRNNplusft_ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgS376b4bzK"
      },
      "source": [
        "'''lstm model'''\n",
        "\n",
        "lstmplusft = Sequential([\n",
        "                   LSTM(10, activation='relu', return_sequences=True, input_shape=(360,31)),\n",
        "                   #Dropout(0.3),\n",
        "                   Flatten(),\n",
        "                   Dense(60)\n",
        "])                  \n",
        "lstmplusft.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrUE6zDa48O5"
      },
      "source": [
        "'''compiling the model'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(0.01)\n",
        "lstmplusft.compile(optimizer=opt, loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGjTMFuG4_R5"
      },
      "source": [
        "'''training phase'''\n",
        "\n",
        "lstmplusft_history = lstmplusft.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cn-T6Oo-Uj0"
      },
      "source": [
        "'''plotting validation and training loss'''\n",
        "\n",
        "plt.plot(lstmplusft_history.history['loss'])\n",
        "plt.plot(lstmplusft_history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zORh84GY-cFf"
      },
      "source": [
        "'''making predictions'''\n",
        "\n",
        "lstmplusft_ypred = lstmplusft.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rfMQT-d-gHa"
      },
      "source": [
        "'''calculating mean absolute error'''\n",
        "\n",
        "mean_absolute_error(y_test, lstmplusft_ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnnPqR0VCIhy"
      },
      "source": [
        "# Without weather"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atFrEhezCZTX"
      },
      "source": [
        "'''removing weather feature'''\n",
        "\n",
        "wo_weather = data.drop('weather', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY2rFjTrCkfu"
      },
      "source": [
        "wo_weather.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E-PNcNvCHR7"
      },
      "source": [
        "'''using 360 hours to predict 60 hours in the future'''\n",
        "\n",
        "n_hours = 360\n",
        "X, Y = [], []\n",
        "for i in range(len(new)):\n",
        "  index = i + n_hours\n",
        "  if index > len(new) - 60:\n",
        "    break\n",
        "  x = wo_weather[i:index]\n",
        "  X.append(x)\n",
        "  y = wo_weather.temperature[index:index+60]\n",
        "  Y.append(y)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGxjHEVTCmPd"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEa04ND5CrBp"
      },
      "source": [
        "'''splitting data into training, validation and test data'''\n",
        "\n",
        "train_index = int(X.shape[0]*0.6)\n",
        "val_index = int(X.shape[0]*0.2)\n",
        "\n",
        "'''training data'''\n",
        "x_train = X[:train_index]\n",
        "y_train = Y[:train_index]\n",
        "\n",
        "'''validation data'''\n",
        "x_val = X[train_index:train_index+val_index]\n",
        "y_val = Y[train_index:train_index+val_index]\n",
        "\n",
        "'''test data'''\n",
        "x_test = X[train_index+val_index:]\n",
        "y_test = Y[train_index+val_index:]\n",
        "\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4pzZ13_Gx-u"
      },
      "source": [
        "# Without weather and wind directions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkqp9I7CG1rp"
      },
      "source": [
        "'''removing weather and wind_direction features'''\n",
        "\n",
        "minuswaw = data.drop(['weather','cos_wind','sin_wind'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5aauBDCHCbc"
      },
      "source": [
        "'''using 360 hours to predict 60 hours in the future'''\n",
        "\n",
        "n_hours = 360\n",
        "X, Y = [], []\n",
        "for i in range(len(new)):\n",
        "  index = i + n_hours\n",
        "  if index > len(new) - 60:\n",
        "    break\n",
        "  x = minuswaw[i:index]\n",
        "  X.append(x)\n",
        "  y = minuswaw.temperature[index:index+60]\n",
        "  Y.append(y)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFx1Kk7lHOu8"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clw97KA3HQev"
      },
      "source": [
        "'''splitting data into training, validation and test data'''\n",
        "\n",
        "train_index = int(X.shape[0]*0.6)\n",
        "val_index = int(X.shape[0]*0.2)\n",
        "\n",
        "'''training data'''\n",
        "x_train = X[:train_index]\n",
        "y_train = Y[:train_index]\n",
        "\n",
        "'''validation data'''\n",
        "x_val = X[train_index:train_index+val_index]\n",
        "y_val = Y[train_index:train_index+val_index]\n",
        "\n",
        "'''test data'''\n",
        "x_test = X[train_index+val_index:]\n",
        "y_test = Y[train_index+val_index:]\n",
        "\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESkj55eIHRnm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}